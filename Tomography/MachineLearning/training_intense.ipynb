{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import models\n",
    "import training\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plts\n",
    "from os.path import join\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def format_data(x):\n",
    "    mean = [x[:, n, :, :].mean() for n in range(x.shape[1])]\n",
    "    std = [x[:, n, :, :].std() for n in range(x.shape[1])]\n",
    "\n",
    "    X = v2.Compose([\n",
    "            torch.from_numpy,\n",
    "            v2.Normalize(mean=mean, std=std),\n",
    "            v2.Resize((64, 64)),\n",
    "        ])(x).to(device)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 1\n",
      "Training loss: 0.00270086\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "Training loss: 0.00294001\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "Training loss: 0.00250214\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "Training loss: 0.00321586\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "Training loss: 0.00231482\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "Training loss: 0.00213476\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "Training loss: 0.00246051\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "Training loss: 0.00209666\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "Training loss: 0.00201559\n",
      "-------------------------------\n",
      "Epoch 10\n"
     ]
    }
   ],
   "source": [
    "orders = range(1,2)\n",
    "\n",
    "for order in orders:\n",
    "    with h5py.File('../../Data/Training/intense_mixed.h5', 'r') as f:\n",
    "        images = format_data(f[f'images_order{order}'][:])\n",
    "        labels = torch.from_numpy(f[f'labels_order{order}'][:]).to(device)\n",
    "\n",
    "    dset = TensorDataset(images, labels)\n",
    "\n",
    "    train_size = int(0.85 * len(dset))\n",
    "    test_size = len(dset) - train_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "    L = images.shape[2]\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    n_channels = 2\n",
    "    n_classes = (order+1)**2-1\n",
    "\n",
    "    model = models.ConvNet(L,L,n_channels, n_classes,[24,40,35],5,nn.ELU,[120,80,40]).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), amsgrad=True)\n",
    "\n",
    "    save_path = f\"../../Results/MachineLearningModels/Intense/Mixed_Order{order}_v2\"\n",
    "\n",
    "    writer = SummaryWriter(save_path)\n",
    "    early_stopping = training.EarlyStopping(patience=50,save_path=save_path)\n",
    "    for t in range(200):\n",
    "        epoch = t+1\n",
    "        print(f\"-------------------------------\\nEpoch {epoch}\")\n",
    "        training.train(model, train_loader, loss_fn, optimizer, device)\n",
    "        val_loss = training.test(model, test_loader, loss_fn, device, epoch, writer, verbose=True)\n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    print(\"Done!\")\n",
    "    writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "def A(dim, j):\n",
    "    assert dim > j+1, \"For a matrix of dimension dim, j must be smaller than dim-1.\"\n",
    "    A = np.zeros(dim, dtype=np.float32)\n",
    "    for i in range(j+1):\n",
    "        A[i] = 1\n",
    "    A[j+1] = -j - 1\n",
    "    A = A / np.linalg.norm(A)\n",
    "    return np.diag(A)\n",
    "\n",
    "def B(dim, j, k):\n",
    "    B = np.zeros((dim, dim), dtype=np.float32)\n",
    "    B[j, k] = 1\n",
    "    B[k, j] = 1\n",
    "    B = B / np.linalg.norm(B)\n",
    "    return B\n",
    "\n",
    "def C(dim, j, k):\n",
    "    C = np.zeros((dim, dim), dtype=np.complex64)\n",
    "    C[j, k] = -1j\n",
    "    C[k, j] = 1j\n",
    "    C = C / np.linalg.norm(C)\n",
    "    return C\n",
    "\n",
    "def get_basis(dim):\n",
    "    As = np.stack([A(dim, j) for j in range(0, dim-1)])\n",
    "    Bs = np.empty((dim * (dim - 1) // 2, dim, dim), dtype=np.float32)\n",
    "    Cs = np.empty((dim * (dim - 1) // 2, dim, dim), dtype=np.complex64)\n",
    "    counter = 0\n",
    "    for j in range(1, dim):\n",
    "        for k in range(0, j):\n",
    "            Bs[counter, :, :] = B(dim, j, k)\n",
    "            Cs[counter, :, :] = C(dim, j, k)\n",
    "            counter+=1\n",
    "    return np.concatenate((As, Bs, Cs), axis=0)\n",
    "\n",
    "def real_representation(rhos):\n",
    "    assert rhos.shape[1] == rhos.shape[2], \"The density matrices must be square.\"\n",
    "    dim = rhos.shape[1]\n",
    "    xs = np.empty((rhos.shape[0],dim**2 - 1), dtype=np.float32)\n",
    "    basis = get_basis(dim)\n",
    "    for rho, x in zip(rhos,xs):\n",
    "        for i, b in enumerate(basis):\n",
    "            x[i] = np.real(np.trace(rho @ b))\n",
    "    return xs\n",
    "\n",
    "def complex_representation(xs):\n",
    "    dim = int(np.sqrt(xs.shape[1] + 1))\n",
    "    basis = get_basis(dim)\n",
    "    \n",
    "    return np.stack([np.eye(dim) / dim + sum(c * b for c, b in zip(x, basis)) for x in xs])\n",
    "\n",
    "\n",
    "def fidelity(rhos1, rhos2):\n",
    "    fids = np.empty(rhos1.shape[0], dtype=np.float32)\n",
    "    for i, (rho1, rho2) in enumerate(zip(rhos1, rhos2)):\n",
    "        sqrt_rho1 = sqrtm(rho1)\n",
    "        fids[i] = np.real(np.trace(sqrtm(sqrt_rho1 @ rho2 @ sqrt_rho1)))**2\n",
    "    return fids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97833139]), array([0.02050678]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = range(1,2)\n",
    "\n",
    "metric = fidelity\n",
    "metrics = np.empty(len(orders))\n",
    "metrics_std = np.empty(len(orders))\n",
    "\n",
    "\n",
    "for order in orders:\n",
    "    with h5py.File('../../Data/Processed/mixed_intense.h5') as f:\n",
    "        images_exp = format_data(f[f'images_order{order}'][:])\n",
    "        labels_exp = f[f'labels_order{order}'][:]\n",
    "    \n",
    "\n",
    "    X_exp = format_data(np.float32(x_exp))\n",
    "    model = torch.load(f\"../../Results/MachineLearningModels/Intense/Mixed_Order{order}/checkpoint.pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        labels_pred = model(X_exp).cpu().numpy()\n",
    "        with h5py.File(\"../../Results/Intense/machine_learning.h5\", 'w-') as out:\n",
    "            out.create_dataset(f'pred_labels_order{order}', data=labels_pred)\n",
    "            out.create_dataset(f'labels_order{order}', data=labels_exp)\n",
    "labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../../Results/Intense/machine_learning.h5','w') as f:\n",
    "    f.create_dataset(\"fids\", data=metrics)\n",
    "    f.create_dataset(\"fids_std\", data=metrics_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModeRecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
