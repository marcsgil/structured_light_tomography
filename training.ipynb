{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import structured_light_tomography.models as models\n",
    "import structured_light_tomography.training as training\n",
    "import structured_light_tomography.dataset_generation as dg\n",
    "import structured_light_tomography.photocount_treatment as pt\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plts\n",
    "from os.path import join\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('TrainingData/pure.h5', 'r') as f:\n",
    "    x = f[f'x_order{order}'][:]\n",
    "    y = f[f'y_order{order}'][:]\n",
    "\n",
    "photocounts = 2048\n",
    "dg.sample_photons(x,photocounts)\n",
    "dset = TensorDataset(torch.from_numpy(x), torch.from_numpy(y))\n",
    "\n",
    "train_size = int(0.8 * len(dset))  # 80% for training\n",
    "test_size = len(dset) - train_size  # 20% for testing\n",
    "\n",
    "train_dataset, test_dataset = random_split(dset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = x.shape[2]\n",
    "loss_fn = training.fidelity_loss\n",
    "n_channels = 2\n",
    "n_classes = 2*(order+1)\n",
    "\n",
    "model = models.ConvNet(L,L,n_channels, n_classes,[24,40,35],5,nn.ELU,[120,80,40]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"runs/Pure/Order1/{photocounts}Photocounts\"\n",
    "\n",
    "writer = SummaryWriter(save_path)\n",
    "early_stopping = training.EarlyStopping(patience=50,save_path=save_path)\n",
    "for t in range(200):\n",
    "    epoch = t+1\n",
    "    print(f\"-------------------------------\\nEpoch {epoch}\")\n",
    "    training.train(model, train_loader, loss_fn, optimizer, device)\n",
    "    val_loss = training.test(model, test_loader, loss_fn, device, epoch, writer, verbose=True)\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "print(\"Done!\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"with h5py.File('ExperimentalData/Intense/pure.h5', 'r') as f:\n",
    "    x_exp = np.float32(f[f'images_order{order}'][:])\n",
    "    y_exp = f[f'coefficients_order{order}'][:]\"\"\"\n",
    "\n",
    "with h5py.File('ExperimentalData/Photocount/datasets.h5', 'r') as f:\n",
    "    histories = f[f'histories_order{order}'][:]\n",
    "    x_exp = np.float32(np.array([pt.array_representation(history,(2,64,64)) for history in histories]))\n",
    "    y_exp = dg.real_representation(f[f'coefficients_order{order}'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcsgil/Desktop/structured_light_tomography/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mean = [x_exp[:, n, :, :].mean() for n in range(x_exp.shape[1])]\n",
    "std = [x_exp[:, n, :, :].std() for n in range(x_exp.shape[1])]\n",
    "\n",
    "X = v2.Compose([\n",
    "        torch.from_numpy,\n",
    "        v2.Normalize(mean=mean, std=std),\n",
    "        v2.Resize((64, 64)),\n",
    "    ])(x_exp).to(device)\n",
    "Y = torch.from_numpy(y_exp).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"runs/Pure/Order1/2048Photocounts/checkpoint.pt\")\n",
    "model.eval()\n",
    "\n",
    "from structured_light_tomography.training import fidelity\n",
    "fidelity(model(X),Y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModeRecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
